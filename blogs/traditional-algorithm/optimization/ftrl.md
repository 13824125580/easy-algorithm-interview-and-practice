## 1.前言
FTRL(Follow The(Proximally) Regularized Leader)算法是Online Learning的一种常用方法。  
传统的机器学习算法，基本的步骤是离线先做数据清洗，ETL，特征工程，然后训练模型上线。模型上线后，一般就是静态的，不会在线上有任何变化。即使是效果不太好，预测误差很大，也只能等下一次更新模型再加以修正。但是一般离线的数据pipeline比较长，而且数据量也比较大，更新模型是个比较费时费力的活。所以传统的训练方式更新模型不是很方便。  
Online Learning是一种另外模型训练的方法，与传统的方法不一样，online learning能根据线上实时反馈的数据，快速训练调整模型参数，使模型即使反映线上的数据变化，从而提高模型的效果。与传统训练方法不同，online 的流程一般为：将预测结果展现给用户，然后收集用户的反馈数据，再来训练新模型，跟控制理论中的闭环系统很类似。  

## 2.FTRL
FTRL的主要目的是提高模型的稀疏度，并且提高模型的精度。具体的算法过程直接参考下面的图  
![在这里插入图片描述](https://github.com/bitcarmanlee/easy-algorithm-interview-photo/blob/master/traditional-algorithm/optimization/FTRL.png)  
上面这张图被很多地方引用，下面我们结合这张图说一下流程。  

上面符号比较多，首先解释一下各符号的含义：  
$\alpha, \beta, \lambda_1, \lambda_2$均为模型的超参数(hyperparameters)，最终训练可以得出超参数的值。  
$T$表示样本的总量，$x_t$表示一条样本。  
$i$表示特征的维度，$d$表示该样本一共有$d$维。  


1.初始化参数$z_i=0, n_i = 0$  
2.对每条样本遍历  

2.1 看$x_t$中哪些维度的值不为0，得到集合$I$  
2.2 遍历集合$I$，得到$w_{t,i}$  
2.3 得到预测概率$p_t$  

3 遍历集合$I$，分别计算$g_i, \sigma_i, z_i, n_i$  

## 3.分析
算法中提到per-coordinate，核心思想是对特征的每一维分开训练更新，而每一维上有不同的学习率。具体就是包含$\lambda$的那一项。  
为什么会是那种形式？简单分析一下，如果有一维特征每个样本都有，学习到的概率大，学习率可以小一些。而如果有一维特征只有很少的样本有，每个包含该特征的样本都很宝贵，这个时候学习率要大一些，让该维特征的学习更充分。  

$$-(\frac{\beta + \sqrt {n_i}}{\alpha} + \lambda_2) ^ {-1}$$  
$n_i$是个正数，如果样本中包含该维特征的样本数越多，迭代过程中$n_i$越大，那么取倒数越小。这样就达到了特征数越多，学习率越小，特征数越少，学习率越大的目的。  

## 4.计算过程分析
算法计算流程中的一些值，我们简单说明一下意义。  
1.$p_t$  
$p_t$是用sigmoid函数计算出来的预测值  
2.$g_i$  
$g_i$是指损失函数在某一个特征维度上的梯度，对于Logisti Regression来说  
$$g_i = (p-y)x_i$$  

3.$\sigma_i$  
是一个中间计算值，没有其他的特殊含义  

4.$z_i$  
也是一个中间计算值，没有其他的特殊含义  

5.$n_i$  
从前面的分析我们可知，$n_i$控制了该维度特征的学习率，与累积的梯度有关系。  