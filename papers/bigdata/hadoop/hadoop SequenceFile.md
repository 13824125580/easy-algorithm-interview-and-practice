## 1 SequenceFile的理解   
1）SequenceFile是Hadoop用来存储二进制形式的对而设计的一种平面文件（Flat File）；    
2）可以把SequenceFile当做一个容器，把所有文件打包到SequenceFile类中可以高效的对小文件进行存储和处理；      
3）SequenceFile文件并不按照其存储的key进行排序存储，SequenceFile的内部类Writer提供了append功能；  
4）SequenceFile中的key和value可以是任意类型Writable或者是自定义的Writable类型；  

## 2 SequenceFile:支持数据压缩（记录压缩，块压缩）
a.无压缩类型：如果没有启用压缩（默认设置），那么每个记录就由他的记录长度（字节数）、键的长度、    
键和值组成。长度字段为四字节。    
b.记录压缩类型：记录压缩格式与无压缩格式基本相同，不同的是值字节是用定义在头部的编码器来压缩的。    
注意，键是不压缩的。    
c.块压缩类型：块压缩一次压缩多个记录，因此它比记录压缩更紧凑，而且一般优先选择。    
当记录的字节数达到最小大小，才会添加到块。改最小值由io.seqfile.compress.blocksize中的属性定义。默认值是1000000字节。格式为记录数、键长度、键、值长度、值。    

## 3.更高层次的容器
对于某些应用而言，需要特殊的数据结构来存储自己的数据。对于基于MapReduce的数据处理，将每个二进制数据的大对象融入自己的文件中并不能实现很高的可扩展性，针对上述情况，Hadoop开发了一组更高层次的容器SequenceFile。  

## 4.将小文件包装
考虑日志文件，其中每一条日志记录是一行文本。如果想记录二进制类型，纯文本是不合适的。这种情况下，Hadoop的SequenceFile类非常合适，因为上述提供了二进制键/值对的永久存储的数据结构。当作为日志文件的存储格式时，可以自己选择键，比如由LongWritable类型表示的时间戳，以及值可以是Writable类型，用于表示日志记录的数量。SequenceFile同样为可以作为小文件的容器。而HDFS和 MapReduce是针对大文件进行优化的，所以通过SequenceFile类型将小文件包装起来，可以获得更高效率的存储和处理。  
