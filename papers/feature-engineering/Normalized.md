在各种模型训练，特征选择相关的算法中，大量涉及到数据归一化的问题。比如最常见的情况是计算距离，如果不同维度之间的取值范围不一样，比如feature1的取值范围是[100,200],feature2的取值范围是[1,2]，如果数据不做归一化处理，会造成feature1在距离计算中占压倒性的优势，feature2完全体现不出来作用。而数据做归一化处理以后，会让各个不同特征对距离计算的贡献大致相同，从而避免人为的数据倾斜。

常见的数据归一化方式如下：
## 1.线性归一化

如果要把输入数据转换到[0,1]的范围，可以用如下公式进行计算：  
$$X_{norm} = \frac{X - X_{min}}{X_{max} - X_{min}}$$  
按以上方式进行归一化以后，输入数据转换到[0,1]的范围。  
有时候我们希望将输入转换到[-1,1]的范围，可以使用以下的公式  
$$X_{norm} = \frac{2*(X - X_{min})}{X_{max} - X_{min}} - 1$$  

以上两种方式，都是针对原始数据做等比例的缩放。其中$X_{norm}$ 是归一化以后的数据，$X$是 原始数据大小，$X_{max}$  $X_{min}$ 分别是原始数据的最大值与最小值。公式简单明了，很容易懂。  
除了将数据缩放到[0,1]或[-1,1]的范围，实际中还经常有其他缩放需求。例如在进行图像处理的过程中，获得的灰度图像的灰度值在[0,255]之间。常用的处理方式之一就是将像素值除以255，就缩放到了[0,1]之间。而在RGB图像转灰度图像的过程中，经常就将灰度值限定在[0,255]之间。

## 2.0均值归一化
0均值归一化将输入的原始数据集归一化为均值为0，方差为1的数据集。具体的归一化公式如下：  
$$z = \frac{x - \mu}{\sigma}$$  
其中，$\mu$,$\sigma$是原始 数据集的均值与标准差。这种方式要求原始数据集的分布近似为正态（高斯）分布。否则归一化的效果很差。  

http://ufldl.stanford.edu/wiki/index.php/数据预处理 中关于0均值归一化的描述：  
特征标准化指的是（独立地）使得数据的每一个维度具有零均值和单位方差。这是归一化中最常见的方法并被广泛地使用（例如，在使用支持向量机（SVM）时，特征标准化常被建议用作预处理的一部分）。在实际应用中，特征标准化的具体做法是：首先计算每一个维度上数据的均值（使用全体数据计算），之后在每一个维度上都减去该均值。下一步便是在数据的每一维度上除以该维度上数据的标准差。  
例子:处理音频数据时，常用 Mel 倒频系数 MFCCs 来表征数据。然而MFCC特征的第一个分量（表示直流分量）数值太大，常常会掩盖其他分量。这种情况下，为了平衡各个分量的影响，通常对特征的每个分量独立地使用标准化处理。  
